{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit4BWSHNVader&Textblob.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q30bOnrc9j3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "0ce58320-6c7b-4591-f3b7-aea60abb3fda"
      },
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import random\n",
        "import re\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob,Word, Blobber\n",
        "nltk.download('stopwords')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRU0BNr19oG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "23473fe7-8501-4fba-9fa0-5111570f944a"
      },
      "source": [
        "# Read test data\n",
        "df = pd.read_csv('saltyhacker.csv')\n",
        "df.head(10)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thu2111</td>\n",
              "      <td>Did those people criticise other epidemiologis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>noisy_boy</td>\n",
              "      <td>I like Aliexpress because most of the times I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lopis</td>\n",
              "      <td>Doesn&amp;#x27;t really matter. The progression of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>aexol</td>\n",
              "      <td>I have added docs generator for GraphQL Editor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>frockington1</td>\n",
              "      <td>I haven;t seen any non sensationalized evidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>alpaca128</td>\n",
              "      <td>&amp;gt; Amazon is the only company that reliably ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>alkonaut</td>\n",
              "      <td>Isn&amp;#x27;t this just a normal water heater?&lt;p&gt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>giantg2</td>\n",
              "      <td>Yes, that&amp;#x27;s a textbook scenario that make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>9wzYQbTYsAIc</td>\n",
              "      <td>There’s something about JavaScript and the len...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Jonnax</td>\n",
              "      <td>What would they be researching?&lt;p&gt;Especially w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0          User                                               Text\n",
              "0           0       thu2111  Did those people criticise other epidemiologis...\n",
              "1           1     noisy_boy  I like Aliexpress because most of the times I ...\n",
              "2           2         lopis  Doesn&#x27;t really matter. The progression of...\n",
              "3           3         aexol  I have added docs generator for GraphQL Editor...\n",
              "4           4  frockington1  I haven;t seen any non sensationalized evidenc...\n",
              "5           5     alpaca128  &gt; Amazon is the only company that reliably ...\n",
              "6           6      alkonaut  Isn&#x27;t this just a normal water heater?<p>...\n",
              "7           7       giantg2  Yes, that&#x27;s a textbook scenario that make...\n",
              "8           8  9wzYQbTYsAIc  There’s something about JavaScript and the len...\n",
              "9           9        Jonnax  What would they be researching?<p>Especially w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbxOt0lnTi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "def sentiment_value(paragraph):\n",
        "    analyser = SentimentIntensityAnalyzer()\n",
        "    result = analyser.polarity_scores(paragraph)\n",
        "    score = result['compound']\n",
        "    return round(score,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rTcjND1nCtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "74b42203-d32a-4c14-9a64-cfb9f605713e"
      },
      "source": [
        "sample = df['Text'][1014]\n",
        "print(sample)\n",
        "print('Sentiment: ')\n",
        "print(sentiment_value(sample))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Okay, now multiply that by 2.\n",
            "Sentiment: \n",
            "0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U1qYouevmC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e5b2e1c8-3824-4090-98dd-303130297203"
      },
      "source": [
        "sample = df['Text'][77]\n",
        "print(sample)\n",
        "print('Sentiment: ')\n",
        "print(sentiment_value(sample))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shoulder pads are back in\n",
            "Sentiment: \n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT6rSOPWvokC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "538b9149-acbe-4e14-a149-ddaa155eb4ad"
      },
      "source": [
        "sample = df['Text'][761]\n",
        "print(sample)\n",
        "print('Sentiment: ')\n",
        "print(sentiment_value(sample))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It sounds like you&#x27;re taking the opportunity, a grammatical error in the op&#x27;s comment, to be combative and argumentative.  Now you&#x27;re just being dismissive of the plight of others and using your command of the language to minimize the situation.<p>The pandemic and quarantine haven&#x27;t just aggravated an untenable situation, they&#x27;re pushing it to the limits.  The poor can&#x27;t afford to not work, the rich can afford to remain in lock down. It&#x27;s happening everywhere, not just in India.<p>There are those of us who can afford to be out of work for a long time, and there are those of us who can continue to work while maintaining quarantine, however there is a significant portion of the population that has run out of reserves and must work to live.  These are people driving trucks, delivering packages, stocking shelves, generally putting themselves at risk while enabling the wealthy to remain quarantined.\n",
            "Sentiment: \n",
            "-0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NETqFC9R-v_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_accuracy(dhn, pred_column):\n",
        "    \"Print accuracy after making predictions\"\n",
        "    acc = accuracy_score(['Text'], df[pred_column])*100\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dkwXxEGnZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#textblob\n",
        "def textblob_score(sentence):\n",
        "    return TextBlob(sentence).sentiment.polarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAw86PXQI92y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to string\n",
        "df['Text'] = df['Text'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUzpzPvcGpiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "01a52612-1979-4f53-e868-ab5d5521f00e"
      },
      "source": [
        "# Convert textblob sentiment score\n",
        "df['textblob_score'] = df['Text'].apply(textblob_score)\n",
        "# Convert float score to category based on binning\n",
        "df['textblob_pred'] = pd.cut(df['textblob_score'], bins=5, labels=[1, 2, 3, 4, 5])\n",
        "df = df.drop('textblob_score', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>textblob_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thu2111</td>\n",
              "      <td>Did those people criticise other epidemiologis...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>noisy_boy</td>\n",
              "      <td>I like Aliexpress because most of the times I ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lopis</td>\n",
              "      <td>Doesn&amp;#x27;t really matter. The progression of...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>aexol</td>\n",
              "      <td>I have added docs generator for GraphQL Editor...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>frockington1</td>\n",
              "      <td>I haven;t seen any non sensationalized evidenc...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... textblob_pred\n",
              "0           0  ...             3\n",
              "1           1  ...             3\n",
              "2           2  ...             3\n",
              "3           3  ...             4\n",
              "4           4  ...             4\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzUJ5ebtNO5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # #Get model accuracy\n",
        "# acc = print_accuracy(df, 'textblob_pred')\n",
        "# print(\"Accuracy: {}\".format(acc[0], acc[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzhuzrZkJ2T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b1afb650-c50d-4bfd-a171-000895869f73"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "def score_vader(sentence, vader):\n",
        "    return vader.polarity_scores(sentence)['compound']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0hfk3CPLT3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8aa0d455-d275-4da2-c103-7419284b452e"
      },
      "source": [
        "# Calculate Vader sentiment score\n",
        "df['vader_score'] = df['Text'].apply(lambda x: score_vader(x, vader))\n",
        "# Convert float score to category based on binning\n",
        "df['vader_pred'] = pd.cut(df['vader_score'], bins=5, labels=[1, 2, 3, 4, 5])\n",
        "df = df.drop('vader_score', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>textblob_pred</th>\n",
              "      <th>vader_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thu2111</td>\n",
              "      <td>Did those people criticise other epidemiologis...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>noisy_boy</td>\n",
              "      <td>I like Aliexpress because most of the times I ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lopis</td>\n",
              "      <td>Doesn&amp;#x27;t really matter. The progression of...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>aexol</td>\n",
              "      <td>I have added docs generator for GraphQL Editor...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>frockington1</td>\n",
              "      <td>I haven;t seen any non sensationalized evidenc...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0          User  ... textblob_pred vader_pred\n",
              "0           0       thu2111  ...             3          1\n",
              "1           1     noisy_boy  ...             3          3\n",
              "2           2         lopis  ...             3          3\n",
              "3           3         aexol  ...             4          3\n",
              "4           4  frockington1  ...             4          3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT10inpFNYqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # # Get model accuracy \n",
        "# acc = print_accuracy(df, 'vader_pred')\n",
        "# print(\"Accuracy: {}\".format(acc[0], acc[1]))\n",
        "\n",
        "\n",
        "\n",
        "# # accuracy: (tp + tn) / (p + n)\n",
        "# accuracy = accuracy_score(df, 'vader_pred')\n",
        "# print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# # f1: 2 tp / (2 tp + fp + fn)\n",
        "# f1 = f1_score(df, 'vader_pred')\n",
        "# print('F1 score: %f' % f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LI2MQ9sZGb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}